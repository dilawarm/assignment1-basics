{
  "train_data_path": "data/encoded/tinystories_train_tokens.npy",
  "val_data_path": "data/encoded/tinystories_val_tokens.npy",
  "vocab_size": 10000,
  "context_length": 256,
  "d_model": 768,
  "num_layers": 12,
  "num_heads": 12,
  "d_ff": 2048,
  "rope_theta": 10000.0,
  "eps": 1e-05,
  "tie_embeddings": false,
  "activation": "leader",
  "use_unet_architecture": true,
  "max_steps": 10000,
  "max_wallclock_hours": 1.5,
  "batch_size": 128,
  "gradient_accumulation_steps": 1,
  "optimizer": "muon_adamw",
  "learning_rate": 0.003,
  "muon_lr": 0.003,
  "adamw_lr": 0.003,
  "embedding_lr": 0.004,
  "lm_head_lr": 0.002,
  "min_learning_rate": 3e-05,
  "warmup_steps": 500,
  "weight_decay": 0.01,
  "momentum": 0.95,
  "ns_iters": 5,
  "beta1": 0.9,
  "beta2": 0.95,
  "grad_clip_norm": 1.0,
  "use_amp": true,
  "use_bfloat16": true,
  "use_gradient_checkpointing": true,
  "gradient_checkpointing_layers": 8,
  "use_tf32": true,
  "compile_model": true,
  "channels_last": false,
  "num_workers": 4,
  "pin_memory": true,
  "prefetch_factor": 2,
  "log_interval": 50,
  "eval_interval": 500,
  "eval_batches": 50,
  "save_interval": 2500,
  "checkpoint_dir": "checkpoints",
  "experiment_name": "tinystories_h100_v1",
  "experiment_description": "TinyStories training",
  "use_wandb": true,
  "wandb_project": "cs336-assignment1",
  "device": "cuda",
  "resume_from": null,
  "auto_resume": true
}