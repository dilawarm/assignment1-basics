{
  "train_data_path": "data/encoded/owt_train_tokens.npy",
  "val_data_path": "data/encoded/owt_valid_tokens.npy",
  "vocab_size": 32000,
  "context_length": 512,
  "d_model": 1024,
  "num_layers": 16,
  "num_heads": 8,
  "d_ff": 4096,
  "rope_theta": 10000.0,
  "eps": 1e-05,
  "tie_embeddings": false,
  "activation": "leader",
  "use_unet_architecture": true,
  "max_steps": 30000,
  "max_wallclock_hours": 1.5,
  "batch_size": 64,
  "gradient_accumulation_steps": 8,
  "optimizer": "muon_adamw",
  "learning_rate": 0.003,
  "muon_lr": 0.003,
  "adamw_lr": 0.003,
  "embedding_lr": 0.004,
  "lm_head_lr": 0.0015,
  "min_learning_rate": 3e-05,
  "warmup_steps": 750,
  "weight_decay": 0.01,
  "momentum": 0.95,
  "ns_iters": 5,
  "beta1": 0.9,
  "beta2": 0.95,
  "grad_clip_norm": 1.0,
  "use_amp": true,
  "use_bfloat16": true,
  "use_gradient_checkpointing": true,
  "gradient_checkpointing_layers": 15,
  "use_tf32": true,
  "compile_model": false,
  "torch_compile_backend": "inductor",
  "torch_empty_cache_steps": 10,
  "channels_last": false,
  "num_workers": 4,
  "pin_memory": true,
  "prefetch_factor": 2,
  "dataloader_drop_last": true,
  "log_interval": 25,
  "eval_interval": 300,
  "eval_batches": 50,
  "save_interval": 1500,
  "checkpoint_dir": "checkpoints",
  "experiment_name": "openwebtext_h100_v1_conservative",
  "experiment_description": "OpenWebText H100 training - Ultra conservative memory settings",
  "use_wandb": true,
  "wandb_project": "cs336-assignment1",
  "device": "cuda",
  "resume_from": null,
  "auto_resume": true
}